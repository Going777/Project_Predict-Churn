{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치\n",
        "%%capture\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Install packages in Colab\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "    # !pip install pandas-profiling==2.*\n",
        "    !pip install pdpbox\n",
        "    !pip install shap\n",
        "    !pip install xgboost"
      ],
      "metadata": {
        "id": "RgH9bsefvamA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwvHZXuduJH8"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rc('axes', unicode_minus=False)\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot, pdp_interact, pdp_interact_plot\n",
        "import shap\n",
        "\n",
        "# from pandas_profiling import ProfileReport\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import OneHotEncoder, TargetEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "2UHDy4k6vRxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "yPk79zl-vUy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scF-T-rH9cJ1"
      },
      "source": [
        "## 모델링\n",
        "* 평가지표 : Accuracy, Recall, F1_score, AUC\n",
        "* 정확도만 가지고 평가하기에는 데이터 불균형으로 인해 우리 예측하고자 하는 타겟(이탈자)을 제대로 예측하지 못하는 경우가 생긴다.\n",
        "* 때문에 정확도와 더불어 Recall, F1_score, AUC를 함께 고려해 주어야 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9RfPAErKsJK"
      },
      "source": [
        "# 모델 평가지표 출력 함수\n",
        "def evaluate(model, X, y):\n",
        "    pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, pred)\n",
        "    recall = recall_score(y, pred)\n",
        "    auc = roc_auc_score(y, pred)\n",
        "    f1 = f1_score(y, pred)\n",
        "    \n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"F1_score: \", f1)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"AUC: \", auc)\n",
        "    print(\"-----------------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwwdPy_7Huqg"
      },
      "source": [
        "# 학습/검증셋으로 나누기\n",
        "train,val = train_test_split(train, train_size=0.8)\n",
        "\n",
        "# 타겟/독립변수로 나누기\n",
        "target = \"churn\"\n",
        "y_train = train[target]\n",
        "X_train = train.drop(columns=target)\n",
        "\n",
        "y_val = val[target]\n",
        "X_val = val.drop(columns=target)\n",
        "\n",
        "y_test = test[target]\n",
        "X_test = test.drop(columns=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkcLpib-oSwx"
      },
      "source": [
        "# 인코딩, 스케일링 진행\n",
        "preprocessing_pipe = Pipeline(\n",
        "    [(\"encoder\",OneHotEncoder(use_cat_names=True)),\n",
        "    (\"scaler\",StandardScaler())])\n",
        "preprocessing_pipe.fit(X_train)\n",
        "\n",
        "X_train_pre = preprocessing_pipe.transform(X_train)\n",
        "X_val_pre = preprocessing_pipe.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P97UAgvc9cMD"
      },
      "source": [
        "### Baseline Model\n",
        "* 타겟 변수의 최빈값으로 예측하는 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8bHj7Y2RZCn"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, auc, confusion_matrix, recall_score\n",
        "\n",
        "major = y_train.mode()[0] # 최빈값 추출\n",
        "pred_train = [major] * len(y_train) # 최빈값으로 트레인 데이터셋 예측\n",
        "\n",
        "pred_val = [major] * len(y_val) # 최빈값으로 검정 데이터셋 예측\n",
        "\n",
        "print(\"--- train --------\")\n",
        "print(\"Accuracy:\",accuracy_score(y_train, pred_train)) # 정확도\n",
        "print(\"F1_score:\",f1_score(y_train, pred_train)) # F1_score\n",
        "print(\"Recall:\",recall_score(y_train, pred_train)) # F1_score\n",
        "print(\"AUC\",roc_auc_score(y_train, pred_train)) # ROC-curve의 면적(AUC)\n",
        "\n",
        "print(\"--- validation --------\")\n",
        "print(\"Accuracy:\",accuracy_score(y_val, pred_val))\n",
        "print(\"F1_score:\",f1_score(y_val, pred_val))\n",
        "print(\"Recall:\",recall_score(y_val, pred_val)) # F1_score\n",
        "print(\"AUC\",roc_auc_score(y_val, pred_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvXZ4xAGkLTX"
      },
      "source": [
        "* 정확도는 어느정도 높지만, 재현율, F1_score, AUC와 같은 다른 모델 평가 지표에서는 형편없는 성능을 보인다\n",
        "* 이는 타겟 변수의 데이터 불균형으로부터 비롯된 것으로 보인다\n",
        "* 해당 부분을 보완하여 모델을 학습시킬 필요가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXa_bBJmlaxj"
      },
      "source": [
        "### UpSampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQVL6v0ZnRy9"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_train_upsample, y_train_upsample = SMOTE(random_state=42).fit_resample(X_train_pre, y_train)\n",
        "pd.DataFrame(y_train_upsample).value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NlY75THwrQ5"
      },
      "source": [
        "* SMOTE방식을 사용하여 데이터 균형을 맞춰주었다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31HRSmCkGt2b"
      },
      "source": [
        "### Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ewQ7136nU1G"
      },
      "source": [
        "logistic1 = LogisticRegression().fit(X_train_upsample, y_train_upsample)\n",
        "\n",
        "print(\"[ training ] \")\n",
        "evaluate(logistic1, X_train_upsample, y_train_upsample)\n",
        "print(\"[ validataion ]\")\n",
        "evaluate(logistic1, X_val_pre, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfYm40B298oN"
      },
      "source": [
        "* 따로 하이퍼파라미터 튜닝없이 기본적인 로지스틱회귀모델을 적용했다\n",
        "* 모델 성능이 나름 괜찮은 것 같다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En00s6ahGt_s"
      },
      "source": [
        "### RandomForest Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMMvasFvG1uI"
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "\n",
        "rf_pipe = Pipeline([(\"rf\", RandomForestClassifier(random_state=2))])\n",
        "\n",
        "param_distribs = {\n",
        "        'rf__n_estimators': randint(low=50, high=500),\n",
        "        'rf__max_depth': randint(1,30),\n",
        "        'rf__max_features': uniform(0,1),\n",
        "    }\n",
        "\n",
        "clf1 = RandomizedSearchCV(\n",
        "    rf_pipe,\n",
        "    param_distributions=param_distribs,\n",
        "    n_iter=30,\n",
        "    cv=3,\n",
        "    scoring=\"f1\",\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=2)\n",
        "\n",
        "clf1.fit(X_train_upsample, y_train_upsample)\n",
        "rf_pipe = clf1.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjHQfJtl_zCR"
      },
      "source": [
        "print(\"[ training ] \")\n",
        "evaluate(rf_pipe, X_train_upsample, y_train_upsample)\n",
        "print(\"[ validataion ]\")\n",
        "evaluate(rf_pipe, X_val_pre, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13FQlkz391D2"
      },
      "source": [
        "* 랜덤포레스트 모델은 하이퍼파라미터 튜닝 후 최적의 파라미터를 적용했지만, 훈련데이터셋에 상당히 과적합된 모델성능을 보여준다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe7s_1uyG10Q"
      },
      "source": [
        "### Xgboost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A89MCLj2-6Ha"
      },
      "source": [
        "xgb_pipe = Pipeline([(\"xgb\",XGBClassifier(random_state=2, n_jobs=-1))])\n",
        "\n",
        "param_distribs = {'xgb__n_estimators': randint(low=50, high=500), \n",
        "                'xgb__learning_rate': [0.05, 0.1, 0.2],\n",
        "                'xgb__max_depth' : randint(1,30),\n",
        "              }\n",
        "\n",
        "\n",
        "clf2 = RandomizedSearchCV(\n",
        "    xgb_pipe,\n",
        "    param_distributions=param_distribs,\n",
        "    n_iter=30,\n",
        "    cv=3,\n",
        "    scoring=\"f1\",\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=2)\n",
        "\n",
        "clf2.fit(X_train_upsample, y_train_upsample)\n",
        "xgb_pipe = clf2.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho2V99LrAD66"
      },
      "source": [
        "print(\"[ training ] \")\n",
        "evaluate(xgb_pipe, X_train_upsample, y_train_upsample)\n",
        "print(\"[ validataion ]\")\n",
        "evaluate(xgb_pipe, X_val_pre, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 여전히 모델의 과적합이 심하다\n",
        "* 이전 모델에서보다 일반화 성능이 더 떨어진 모습이다"
      ],
      "metadata": {
        "id": "Yx5Cfyoep4Ad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kguJ1rs1urGG"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDoZDvs_CUxI"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_pipe = Pipeline([(\"lgbm\", LGBMClassifier(random_state=2, n_jobs=-1, objective=\"binary\"))]    \n",
        ")\n",
        "\n",
        "param_distributions = {'lgbm__n_estimators': randint(low=50, high=500), \n",
        "              'lgbm__learning_rate': [None, 0.05, 0.1, 0.2],\n",
        "              'lgbm__max_depth' : randint(1,15),\n",
        "              'lgbm__num_leaves': randint(1,50),\n",
        "              'lgbm__max_features': uniform(0,1),\n",
        "              }\n",
        "\n",
        "\n",
        "clf3 = RandomizedSearchCV(\n",
        "    lgbm_pipe,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=40,\n",
        "    cv=3,\n",
        "    scoring=\"f1\",\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=2)\n",
        "\n",
        "clf3.fit(X_train_upsample, y_train_upsample)\n",
        "lgbm_pipe = clf3.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6RuIQ3SD0NB"
      },
      "source": [
        "print(\"[ training ]\")\n",
        "evaluate(lgbm_pipe, X_train_upsample, y_train_upsample)\n",
        "print(\"[ validataion ]\")\n",
        "evaluate(lgbm_pipe, X_val_pre, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS5mRA9rfkd-"
      },
      "source": [
        "* LGBM 역시 과적합이 존재하긴 하지만 검정 테스트셋에서도 그렇게 나쁜 성능을 보이진 않고 있다\n",
        "* 무엇보다 모델이 빨리 돌아가서 시간적인 측면에서 장점이 크다\n",
        "* LGBM을 최종모델로 선정해보려 한다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-M0rlJdQF3j"
      },
      "source": [
        "X_test_pre = preprocessing_pipe.transform(X_test)\n",
        "\n",
        "print(\"[ test ]\")\n",
        "evaluate(lgbm_pipe, X_test_pre, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pqL_yS7Ip5"
      },
      "source": [
        "* test set에서도 검증 데이터셋에서 확인했던 모델 성능과 비슷한 결과를 내주었다\n",
        "* 어느정도 과적합이 있긴했지만 일반화 성능도 나쁘지는 않은 것 같다\n",
        "* BaselineModel과 비교했을 때, F1_score, Recall과 같은 지표에서 성능이 굉장히 개선되었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Z95LSXLCgA"
      },
      "source": [
        "## 분석결과 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njx8g-W7LHFu"
      },
      "source": [
        "### 변수 중요도\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8DWRNWevHv7"
      },
      "source": [
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    lgbm_pipe.named_steps[\"lgbm\"],\n",
        "    scoring=\"f1\",\n",
        "    n_iter=5,\n",
        "    random_state=2\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_pre, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tigputRMAAd"
      },
      "source": [
        "import eli5\n",
        "enc = preprocessing_pipe.named_steps[\"encoder\"]\n",
        "feature_names = enc.get_feature_names()\n",
        "\n",
        "\n",
        "perm_imp_df = pd.DataFrame()\n",
        "perm_imp_df[\"feature\"] = feature_names\n",
        "perm_imp_df[\"importance\"] = permuter.feature_importances_\n",
        "perm_imp_df = perm_imp_df.sort_values([\"importance\"],ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=perm_imp_df)\n",
        "plt.title(\"Permutation Importance by LGBM\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQDS87HaHklK"
      },
      "source": [
        "* Feature Engineering으로 만들어낸 변수들이 어느정도 상위에 랭크하고 있다\n",
        "* 상위랭크 : contract_month_to_month, tenure, internetservice_Fiber optic, contract_two_year, predicted_diff\n",
        "* 하위랭크 : streamingmovies, seniorcitizenn, contract_one_year, deviceprotection, techsupport, onlinebackup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1upq1EmL8pj"
      },
      "source": [
        "# 상위랭크(top3)에 위치한 변수들의 영향도를 살펴보자\n",
        "features = perm_imp_df[\"feature\"].iloc[:3].tolist()\n",
        "X_test_df = pd.DataFrame(X_test_pre, columns=feature_names)\n",
        "\n",
        "for feature in features:\n",
        "    isolated = pdp_isolate(\n",
        "        model = lgbm_pipe,\n",
        "        dataset=X_test_df,\n",
        "        model_features = feature_names,\n",
        "        feature=feature\n",
        "        # feature = feature,\n",
        "        # grid_type = \"percentile\",\n",
        "        # num_grid_points = 10\n",
        "    )\n",
        "    sns.set(font_scale=2)\n",
        "    pdp_plot(isolated, feature_name=feature);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20XAdvI_AviQ"
      },
      "source": [
        "* EDA 분석에서 분석했던 결과와 거의 동일한 영향을 미치고 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dsnM-wWuaai"
      },
      "source": [
        "## 모델의 한계\n",
        "* 데이터의 크기가 작아서 과적합될 우려가 있다\n",
        "* 과적합 문제를 완전히 해결하진 못했다\n",
        "* 데이터 수급이 굉장히 간단하게 되어 있고, 변수 자체도 정제되어 들어와있는데, 이러한 데이터를 만나기는 쉽지 않다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKT3Bfvvuaez"
      },
      "source": [
        "## 모델의 유용성\n",
        "* 해당 모델에서 살펴봤던 타겟변수와 피쳐들의 관계에 대한 분석은 추후 고객 유지 방법을 모색할 때 유용한 지표로 사용될 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TTN2IqKveRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}